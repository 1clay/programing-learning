# 2022.5.27 rl-3

### 使用PyTorch进行深度学习

▪  PyTorch库的特点和安装细节（假定你已经熟悉了DL的基础知识）。
▪  基于PyTorch的高级库，其目的是简化常见的DL问题。
▪  PyTorch Ignite库，会在一些例子中使用。

#### 3.1　张量

有三种方法可以在PyTorch中创建张量：
▪  通过调用所需类型的构造函数。
▪  通过将NumPy数组或Python列表转换为张量。在这种情况下，类型将从数组的类型中获取。
▪  通过要求PyTorch创建带有特定数据的张量。例如，可以使用torch.zeros()函数创建一个全为零的张量。

#### 3.2	梯度

最根本的区别是如何计算梯度。有两种方法：
▪  静态图：在这种方法中，需要提前定义计算，并且以后也不能更改。在进行任何计算之前，DL库将对图进行处理和优化。此模型在TensorFlow（<2的版本）、Theano和许多其他DL工具库中均已实现。
▪  动态图：不需要预先精确地定义将要执行的图；只需要在实际数据上执行希望用于数据转换的操作。在此期间，库将记录执行的操作的顺序，当要求它计算梯度时，它将展开其操作历史，积累网络参数的梯度。这种方法也称为notebook gradient，它已在PyTorch、Chainer和一些其他库中实现。

##### 每个张量都有几个与梯度相关的属性：

▪  grad：张量的梯度，与原张量形状相同。
▪  is_leaf：如果该张量是由用户构造的，则为True；如果是函数转换的结果，则为False。
▪  requires_grad：如果此张量需要计算梯度，则为True。此属性是从叶张量继承而来，叶张量从张量构建过程（torch.zeros()或torch.tensor()等）中获得此值。默认情况下，构造函数的requires_grad = False，如果要计算张量梯度，则需明确声明。

##### 所有nn.Module子类提供的方法。如下：

▪  parameters()：此函数返回所有需要进行梯度计算的变量的迭代器（即模块权重）。
▪  zero_grad()：此函数将所有参数的梯度初始化为零。
▪  to(device)：此函数将所有模块参数移至给定的设备（CPU或GPU）。
▪  state_dict()：此函数返回一个包含所有模块参数的字典，对于模型序列化很有用。
▪  load_state_dict()：此函数使用状态字典来初始化模块。
所有的类都可在文档（http://pytorch.org/docs）中找到。

##### nn.Module为其子类提供了相当丰富的功能：

▪  它记录当前模块的所有子模块。例如，构建块可以具有两个前馈层，可以以某种方式使用它们来执行代码块的转换。
▪  提供处理已注册子模块的所有参数的函数。可以获取模块参数的完整列表（parameters()方法）将其梯度置零（zero_grads()方法），将其移至CPU或GPU（to(device)方法），序列化和反序列化模块（state_dict()和load_state_dict()），甚至可以用自己的callable执行通用的转换逻辑（apply()方法）。
▪  建立了Module针对数据的约定。每个模块都需要覆盖forward()方法来执行数据的转换。
▪  还有更多的函数，例如注册钩子函数以调整模块转换逻辑或梯度流，它们更加适合高级的使用场景。

##### 最常用的标准损失函数是：

▪  nn.MSELoss：参数之间的均方误差，是回归问题的标准损失。
▪  nn.BCELoss和nn.BCEWithLogits：二分类交叉熵损失。前者期望输入是一个概率值（通常是Sigmoid层的输出），而后者则假定原始分数为输入并应用Sigmoid本身。第二种方法通常在数值上更稳定、更有效。这些损失（顾名思义）经常用于分类问题。
▪  nn.CrossEntropyLoss和nn.NLLLoss：著名的“最大似然”标准，用于多类分类问题。前者期望的输入是每个类的原始分数，并在内部应用LogSoftmax，而后者期望将对数概率作为输入。

##### 在torch.optim包中，PyTorch提供了许多流行的优化器实现，其中最广为人知的是：

▪  SGD：具有可选动量的普通随机梯度下降算法。
▪  RMSprop：Geoffrey Hinton提出的优化器。
▪  Adagrad：自适应梯度优化器。
▪  Adam：一种非常成功且流行的优化器，是RMSprop和Adagrad的组合。

##### DL从业人员已制定出在训练期间应观察的事项清单，通常包括以下内容：

▪  损失值，通常由基本损失和正则化损失等几部分组成。应该同时观察总损失和各个组成部分。
▪  训练和测试数据集的验证结果。
▪  梯度和权重的统计信息。
▪  网络计算出来的值。例如，如果你正在解决分类问题，肯定要测量所预测的类概率计算出的熵。在回归问题中，原始预测值可以提供有关训练的大量数据。
▪  学习率和其他超参（如果它们也是随时间调整的话）。

