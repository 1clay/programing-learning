# 2022.5.17

### 机器学习中的目标函数、损失函数、代价函数有什么区别？

首先给出结论：损失函数和代价函数是同一个东西，目标函数是一个与他们相关但更广的概念，对于目标函数来说在有约束条件下的最小化就是损失函数（loss function）。

举个例子解释一下:（图片来自Andrew Ng Machine Learning公开课视频）

![1a34ac5c0afc6fadadee04c92015ca5](C:\Users\11212\Desktop\1a34ac5c0afc6fadadee04c92015ca5.png)

上面三个图的函数依次为 ![[公式]](https://www.zhihu.com/equation?tex=f_%7B1%7D%28x%29) , ![[公式]](https://www.zhihu.com/equation?tex=f_%7B2%7D%28x%29) , ![[公式]](https://www.zhihu.com/equation?tex=f_%7B3%7D%28x%29) 。我们是想用这三个函数分别来拟合Price，Price的真实值记为 ![[公式]](https://www.zhihu.com/equation?tex=Y) 。

我们给定 ![[公式]](https://www.zhihu.com/equation?tex=x) ，这三个函数都会输出一个 ![[公式]](https://www.zhihu.com/equation?tex=f%28X%29) ,这个输出的 ![[公式]](https://www.zhihu.com/equation?tex=f%28X%29) 与真实值 ![[公式]](https://www.zhihu.com/equation?tex=Y) 可能是相同的，也可能是不同的，为了表示我们拟合的好坏，我们就用一个函数来**度量拟合的程度**，比如：

![[公式]](https://www.zhihu.com/equation?tex=L%28Y%2Cf%28X%29%29+%3D+%28Y-f%28X%29%29%5E2) ，这个函数就称为损失函数(loss function)，或者叫代价函数(cost function)。损失函数**越小**，就代表模型**拟合的越好**。

那是不是我们的目标就只是让loss function越小越好呢？还不是。

这个时候还有一个概念叫风险函数(risk function)。风险函数是损失函数的期望，这是由于我们输入输出的 ![[公式]](https://www.zhihu.com/equation?tex=%28X%2CY%29) 遵循一个联合分布，但是这个联合分布是未知的，所以无法计算。但是我们是有历史数据的，就是我们的训练集， ![[公式]](https://www.zhihu.com/equation?tex=f%28X%29) 关于训练集的**平均损失**称作经验风险(empirical risk)，即 ![[公式]](https://www.zhihu.com/equation?tex=%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi%3D1%7D%5E%7BN%7DL%28y_%7Bi%7D%2Cf%28x_%7Bi%7D%29%29) ，所以我们的目标就是最小化 ![[公式]](https://www.zhihu.com/equation?tex=%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi%3D1%7D%5E%7BN%7DL%28y_%7Bi%7D%2Cf%28x_%7Bi%7D%29%29) ，称为**经验风险最小化**。

到这里完了吗？还没有。

如果到这一步就完了的话，那我们看上面的图，那肯定是最右面的 ![[公式]](https://www.zhihu.com/equation?tex=f_3%28x%29) 的经验风险函数最小了，因为它对历史的数据拟合的最好嘛。但是我们从图上来看 ![[公式]](https://www.zhihu.com/equation?tex=f_3%28x%29)肯定不是最好的，因为它**过度学习**历史数据，导致它在真正预测时效果会很不好，这种情况称为过拟合(over-fitting)。

为什么会造成这种结果？大白话说就是它的函数太复杂了，都有四次方了，这就引出了下面的概念，我们不仅要让经验风险最小化，还要让**结构风险最小化**。这个时候就定义了一个函数 ![[公式]](https://www.zhihu.com/equation?tex=J%28f%29) ，这个函数专门用来度量**模型的复杂度**，在机器学习中也叫[正则化](https://www.zhihu.com/search?q=正则化&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A209358209})(regularization)。常用的有 ![[公式]](https://www.zhihu.com/equation?tex=L_1) , ![[公式]](https://www.zhihu.com/equation?tex=L_2) 范数。

到这一步我们就可以说我们最终的优化函数是：![[公式]](https://www.zhihu.com/equation?tex=min%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi%3D1%7D%5E%7BN%7DL%28y_%7Bi%7D%2Cf%28x_%7Bi%7D%29%29%2B%5Clambda+J%28f%29) ，即最优化经验风险和结构风险，而这个函数就被称为**目标函数**。

结合上面的例子来分析：最左面的 ![[公式]](https://www.zhihu.com/equation?tex=f_1%28x%29) 结构风险最小（模型结构最简单），但是经验风险最大（对历史数据拟合的最差）；最右面的 ![[公式]](https://www.zhihu.com/equation?tex=f_3%28x%29) 经验风险最小（对历史数据拟合的最好），但是结构风险最大（模型结构最复杂）;而 ![[公式]](https://www.zhihu.com/equation?tex=f_2%28x%29) 达到了二者的良好**平衡**，最适合用来预测未知数据集。

损失、过拟合、欠拟合、